{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding a particular object.\n",
    "\n",
    "cv2.matchTemplate(where_bw,template,cv2.TM_CCOEFF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "where = cv2.imread(\"C:/Users/User/User/Desktop/Where_is.jpg\")\n",
    "cv2.imshow(\"Where we need to find.\", where)\n",
    "cv2.waitKey()\n",
    "\n",
    "template = cv2.imread(\"C:/Users/User/User/Desktop/temp.jpg\")\n",
    "cv2.imshow(\"What we need\", template)\n",
    "cv2.waitKey()\n",
    "\n",
    "where_bw = cv2.cvtColor(where,cv2.COLOR_BGR2GRAY)\n",
    "template = cv2.cvtColor(template,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "result = cv2.matchTemplate(where_bw,template,cv2.TM_CCOEFF)\n",
    "min_value, max_value, min_loc, max_loc = cv2.minMaxLoc(result)\n",
    "\n",
    "topleft = max_loc\n",
    "bottom_right = (topleft[0]+50,topleft[1]+50)\n",
    "cv2.rectangle(where,topleft,bottom_right,(0,0,255),5)\n",
    "\n",
    "cv2.imshow(\"Located\", where)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding Corners\n",
    "\n",
    "1. Harris corner detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "chess = cv2.imread(\"C:/Users/User/User/Desktop/chess.jpg\")\n",
    "cv2.imshow(\"Where we need to find.\", chess)\n",
    "cv2.waitKey()\n",
    "\n",
    "gray = cv2.cvtColor(chess,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "harris_corners = cv2.cornerHarris(gray,3,3,0.05)\n",
    "\n",
    "kernel = np.ones((7,7),np.uint8)\n",
    "harris_corners = cv2.dilate(harris_corners, kernel, iterations = 1)\n",
    "\n",
    "chess[harris_corners > 0.025*harris_corners.max()] = [255,127,127]\n",
    "\n",
    "cv2.imshow('Harris Corners', chess)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improved Corner Detection using - Good features to track"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "chess = cv2.imread(\"C:/Users/User/User/Desktop/chess.jpg\")\n",
    "cv2.imshow(\"Where we need to find.\", chess)\n",
    "cv2.waitKey()\n",
    "gray = cv2.cvtColor(chess,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "corners = cv2.goodFeaturesToTrack(gray,100,0.01,15)\n",
    "\n",
    "for corner in corners:\n",
    "    x,y = corner[0]\n",
    "    x = int(x)\n",
    "    y = int(y)\n",
    "    cv2.rectangle(chess,(x-2,y-2),(x+2,y+2),(0,255,0),2)\n",
    "\n",
    "cv2.imshow('Corners Found', chess)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### cv2.goodFeaturesToTrack(input image,number of corners,quality,min distance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SIFT : Scale Invarient Feature Transform\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "chess = cv2.imread(\"C:/Users/User/User/Desktop/chess.jpg\")\n",
    "cv2.imshow(\"Where we need to find.\", chess)\n",
    "cv2.waitKey()\n",
    "gray = cv2.cvtColor(chess,cv2.COLOR_BGR2GRAY)\n",
    " \n",
    "sift = cv2.SIFT_create()\n",
    "\n",
    "keypoints = sift.detect(gray, None)\n",
    "print(\"Number of Keypoints located \", len(keypoints))\n",
    "\n",
    "chess = cv2.drawKeypoints(chess,keypoints, flags = cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "\n",
    "cv2.imshow('Feature Metod - SIFT', chess)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SURF, FAST, BRIEF, ORB\n",
    "\n",
    "ORB inbuilt so implementation shown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Keypoints located  695\n"
     ]
    }
   ],
   "source": [
    "chess = cv2.imread(\"C:/Users/User/User/Desktop/chess.jpg\")\n",
    "cv2.imshow(\"Where we need to find.\", chess)\n",
    "cv2.waitKey()\n",
    "gray = cv2.cvtColor(chess,cv2.COLOR_BGR2GRAY)\n",
    "cv2.imshow(\"Where we need to find.\", gray)\n",
    "cv2.waitKey()\n",
    "orb = cv2.ORB_create(5000)\n",
    "\n",
    "keypoints = orb.detect(gray, None)\n",
    "print(\"Number of Keypoints located \", len(keypoints))\n",
    "\n",
    "cv2.drawKeypoints(chess, keypoints,chess, flags = cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "\n",
    "cv2.imshow('Feature Metod - ORB', chess)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MINI-Project Object detection using ORB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ORB_detector(new_image, image_template):\n",
    "    \n",
    "    image1 = cv2.cvtColor(new_image,cv2.COLOR_BGR2GRAY)\n",
    "    image2 = image_template\n",
    "    \n",
    "    orb = cv2.ORB_create(5000,1.2)\n",
    "    \n",
    "    (kp1,des1) = orb.detectAndCompute(image1,None)\n",
    "    (kp2,des2) = orb.detectAndCompute(image2,None)\n",
    "    \n",
    "    bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck = True)\n",
    "    \n",
    "    matches = bf.match(des1,des2)\n",
    "    \n",
    "    matches = sorted(matches, key = lambda val: val.distance)\n",
    "    \n",
    "    return len(matches)\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "image_template = cv2.imread(\"C:/Users/User/User/Desktop/4.jpg\",0)\n",
    "## Basically the template is for London Bridge. Take your own photos and check it out. \n",
    "\n",
    "while True:\n",
    "    \n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    height, width = frame.shape[:2]\n",
    "    \n",
    "    tlx = int(width/3) ; tly = int((height/2) + (height/4))\n",
    "    brx = int(2*width/3); bry = int((height/2) - (height/4))\n",
    "    \n",
    "    cv2.rectangle(frame,(tlx,tly),(brx,bry),255,3)\n",
    "    \n",
    "    cropped = frame[bry:tly,tlx:brx]\n",
    "    \n",
    "    frame = cv2.flip(frame,1)\n",
    "    \n",
    "    matches = ORB_detector(cropped, image_template)\n",
    "    \n",
    "    output_string = 'Matches =' + str(matches)\n",
    "    cv2.putText(frame,output_string,(50,450),cv2.FONT_HERSHEY_COMPLEX,2,(250,0,150),2)\n",
    "    \n",
    "    threshold = 200\n",
    "    \n",
    "    if matches > threshold:\n",
    "        cv2.rectangle(frame,(tlx,tly),(brx,bry),(0,255,0),3)\n",
    "        cv2.putText(frame,output_string,(50,450),cv2.FONT_HERSHEY_COMPLEX,2,(250,0,150),2)\n",
    "        \n",
    "    cv2.imshow(\"Object detector using ORB\", frame)\n",
    "    \n",
    "    if cv2.waitKey(1) == 13:\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
